{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리들을 불러옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 셀레니움 웹드라이버를 이용해서 다음 카페 모바일의 로그인 페이지를 열어줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/PyApp/driver/chromedriver')\n",
    "# 설치 폴더에 주의합니다. \n",
    "\n",
    "driver.get('https://logins.daum.net/accounts/loginform.do?mobilefull=1&category=cafe&url=http%3A%2F%2Fm.cafe.daum.net%2F_myCafe%3Fnull')\n",
    "\n",
    "time.sleep(5)\n",
    "# 페이지 전환시에는 적당한 시간을 줍니다. \n",
    "# 1. 과도한 크롤링 방지.\n",
    "# 2. 페이지 전환이 완료되기 전에 다음 명령 실행되는 것 방지."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 아이디와 비밀 번호 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=74.0.3729.131)\n  (Driver info: chromedriver=74.0.3729.6 (255758eccf3d244491b8a1317aa76e1ce10d57e9-refs/branch-heads/3729@{#29}),platform=Windows NT 10.0.17763 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-97a02bd45d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 수동으로 웹 브라우저에 직접 입력 후 건너뛰어도 됩니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"//*[@id=\"id\"]\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'midikid'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# id를 입력한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"//*[@id=\"inputPwd\"]\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tkfka95@dm'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 패스워드를 입력한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"//*[@id=\"loginBtn\"]\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 입력 버튼 클릭.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\pyapp\\daum-cafe-crawler\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\pyapp\\daum-cafe-crawler\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\pyapp\\daum-cafe-crawler\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mc:\\pyapp\\daum-cafe-crawler\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=74.0.3729.131)\n  (Driver info: chromedriver=74.0.3729.6 (255758eccf3d244491b8a1317aa76e1ce10d57e9-refs/branch-heads/3729@{#29}),platform=Windows NT 10.0.17763 x86_64)\n"
     ]
    }
   ],
   "source": [
    "# 수동으로 웹 브라우저에 직접 입력 후 건너뛰어도 됩니다. \n",
    "\n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"id\"]\"\"\").send_keys('midikid') # id를 입력한다. \n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"inputPwd\"]\"\"\").send_keys('tkfka95@dm') # 패스워드를 입력한다. \n",
    "driver.find_element_by_xpath(\"\"\"//*[@id=\"loginBtn\"]\"\"\").click() # 입력 버튼 클릭.\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 까페 이름, 게시판 주소 등을 보기 좋게 여기쯤 지정해 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAFE_NAME = 'ssaumjil' \n",
    "# 까페 이름을 넣어준다. 예제는 이종격투기... \n",
    "\n",
    "BOARD_NAME = 'EnXG' \n",
    "# 게시판 주소의 마지막 4자리를 넣어준다. \n",
    "# http://m.cafe.daum.net/ssaumjil/EnXG\n",
    "\n",
    "DB = CAFE_NAME + '_m_article.db'\n",
    "# DB 이름도 지정해 줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 게시판으로 이동"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "driver.get('http://m.cafe.daum.net/%s/%s?boardType=' % (CAFE_NAME, BOARD_NAME))\n",
    "# 이제 위에서 지정한 까페의 게시판으로 이동합니다. \n",
    "# 바로 게시물로 이동해도 됩니만.. \n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 데이터베이스 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB)\n",
    "cur = conn.cursor()\n",
    "\n",
    "sql = 'CREATE TABLE IF NOT EXISTS \"' + BOARD_NAME + \\\n",
    "  '\"(\"num\" INTEGER NOT NULL UNIQUE, \"subject\" TEXT, ' + \\\n",
    "  '\"nick\" TEXT, \"write_time\" TEXT, \"views\" INTEGER, ' + \\\n",
    "  '\"url\" TEXT, \"contents\" TEXT, PRIMARY KEY(\"num\"));'\n",
    "\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "sql = 'CREATE TABLE IF NOT EXISTS \"' + BOARD_NAME + \\\n",
    "  '_cmt\" (\"cmt_num\" TEXT NOT NULL UNIQUE, \"cmt_reply\" INTEGER, \"cmt_writer\" TEXT, \"cmt_time\" TEXT, \"cmt_txt\" TEXT, PRIMARY KEY(\"cmt_num\"));'\n",
    "\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 캡쳐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_num = input('저장할 게시물 번호 + 엔터: ')\n",
    "\n",
    "num = int(inp_num) #뒤에 DB에 정수로 저장할 거니까 형변환 해줍시다. \n",
    "\n",
    "url = 'http://m.cafe.daum.net/%s/%s/%s' % (CAFE_NAME, BOARD_NAME, inp_num)\n",
    "driver.get(url) # 게시물의 주소로 이동합니다. \n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이제 다음 줄에서 페이지 소스를 얻은 것을 마지막(?)으로 셀레니움의 역할은 끝납니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source  # 셀레니움의 페이지 소스를 html로... \n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "# 뷰티플 숩은 html을 받아서 html 파서를 돌려서 soup로 보냅니다. \n",
    "\n",
    "# repr(soup)\n",
    "\n",
    "#### 게시물의 구성요소들을 하나씩 찾아봅니다. \n",
    "\n",
    "subject = soup.body.find('h3', class_='tit_subject')\n",
    "\n",
    "# 숩은 엘리멘트 트리와 달리 class명을 이용해서 h3을 바로 찾아줍니다. \n",
    "# 같은 태그에 클래스명까지 겹치면 겹치는 노드 중 첫번째 노드가 검색됩니다. \n",
    "# 이 HTML 문서에서 'tit_subject' 클래스는 한번만 사용됩니다. ^^\n",
    "# 개발자 도구의 검색 기능을 이용해 보십시오. \n",
    "\n",
    "if subject is None:\n",
    "    # None 객체에 .get_text() 메소드를 붙이면 에러가 발생합니다. \n",
    "    # 연속 크롤링시에는 에러를 최대한 피해줘야 합니다. \n",
    "    # 그래서 if 문으로 사전에 걸러주는 겁니다. \n",
    "    # 대신 코드가 지저분해지기 시작합니다. \n",
    "    print(url, '지워진 게시물입니다.')\n",
    "else:\n",
    "    # 지워진 게시물이 아닌 경우 이하를 계속 실행합니다. \n",
    "    subject = subject.get_text(strip=True)  \n",
    "    \n",
    "    # 뷰티플 숩은 XPath를 지원하지 않습니다. \n",
    "    # 작성자 항목은 직접적인 태그로 감싸지지도 않았습니다. \n",
    "    # 이런 경우에는 옆 노드를 찾아서 그 노드의 이웃으로 찾아야 합니다. \n",
    "    # XPath의 편리함이 떠오를 따름입니다. ㅠ,.ㅠ \n",
    "\n",
    "    # 다음은 익명 게시판기능도 있어서 작성자가 공란인 경우도 있습니다. \n",
    "    # 미리 걸러줘야 합니다. \n",
    "    \n",
    "    if soup.body.find('span', class_='txt_subject').find('span', class_='sr_only').get_text() == '작성자':\n",
    "        nick = soup.body.find('span', class_='sr_only').next_sibling\n",
    "    else:\n",
    "        nick = ''\n",
    "\n",
    "    # 작성시간과 조회수를 찾아봅시다. \n",
    "    # 클래스 명이 지정되어 있습니만, \n",
    "    # 작성시간, 조회수 2군데에서 사용되었네요. \n",
    "    # 이런 경우는 find_all()로 작성시간과 조회수를 동시에 찾아낸 뒤 \n",
    "    # [0], [1]로 리스트의 요소를 하나씩 뽑아내야 겠네요. \n",
    "\n",
    "    # num_subject라는 변수명은 해당 노드의 클래스명에서 따왔습니다. \n",
    "    # 프로그래머의 가장 큰 고민은 변수 이름을 짓는 것이라고 합니다.  \n",
    "    # 원본을 그대로 쓰면 그런 고민을 할 필요가 없어집니다. \n",
    "    # 하지만 .... 직관적이지 않은 변수명 같습니다...\n",
    "        \n",
    "    num_subject = soup.body.find_all('span', class_='num_subject')\n",
    "    write_time = num_subject[0].get_text()\n",
    "    views = num_subject[1].get_text()\n",
    "\n",
    "    print(num, subject, nick, write_time, views, url)\n",
    "\n",
    "    # 본문\n",
    "    \n",
    "    # 본문은 친절하게 id='article' 안에 잘 들어있습니다. \n",
    "    # 이런 경우는 id는 유일하니까 고민이 별로 없어집니다. \n",
    "    # 바로 find로 찾으면 됩니다. \n",
    "\n",
    "    contents = soup.body.find('div', id='article').get_text('\\n', strip=True)\n",
    "    print(contents)\n",
    "\n",
    "    \n",
    "    # 위에서 사용했던 변수들을 모아서 DB에 넣어줍니다.\n",
    "    # DB에 관한 설명은 별도로 하지 않겠습니다.  \n",
    "    # 제가 첫 시간에 알려드렸던 사이트들을 보시면 될 것 같습니다. \n",
    "    \n",
    "    conn = sqlite3.connect(DB)\n",
    "    cur = conn.cursor()\n",
    "    sql = \"replace into %s(num,subject,nick,write_time,views,url,contents) values (?,?,?,?,?,?,?)\" % BOARD_NAME\n",
    "    cur.execute(sql, (num, subject, nick, write_time, views, url, contents))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    # 댓글 개수\n",
    "    cmt_total = soup.body.find('article', id='mArticle').find('span', class_=\"num_total\").get_text()\n",
    "    print('댓글 개수 :', cmt_total)\n",
    "\n",
    "    # 댓글\n",
    "\n",
    "    # 댓글 페이지로 이동\n",
    "    driver.get('http://m.cafe.daum.net/{0}/{1}/{2}/comments'.format(CAFE_NAME,BOARD_NAME,inp_num))\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # 크롤링한 페이지에서 페이지 슷자 추출(cmt_index)\n",
    "    cmt_page_max = int(soup.body.find('span', id=\"pagingNav\").find_all('span', class_=\"num_page\").pop().get_text())\n",
    "\n",
    "    print('cmt_page_max', cmt_page_max)\n",
    "    for i in range(cmt_page_max):\n",
    "        j = cmt_page_max-i\n",
    "        \n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        cmt_all = soup.body.find('ul' ,id=\"commentList\").find_all('li')\n",
    "        \n",
    "        for k in cmt_all:\n",
    "            if k.div.span.find_all('span', class_=\"txt_bar\"):\n",
    "                if k['class'] == ['reply_on']:\n",
    "                    cmt_reply = True\n",
    "                    print('ㄴ', end='')\n",
    "                else:\n",
    "                    cmt_reply = False\n",
    "\n",
    "                cmt_num = inp_num +'_'+ k['id'].split('comment_')[1]\n",
    "                cmt_writer = k.div.find('span', class_='sr_only').next_sibling\n",
    "                cmt_time = k.div.span.find('span', class_=\"num_info\").get_text()\n",
    "                cmt_txt = k.div.find('span', class_='txt_detail').get_text(strip=True)\n",
    "                print(cmt_num, '[', cmt_writer, ']', cmt_time, cmt_txt)\n",
    "                \n",
    "                conn = sqlite3.connect(DB)\n",
    "                cur = conn.cursor()\n",
    "                sql = \"replace into '%s_cmt'(cmt_num,cmt_reply,cmt_writer,cmt_time,cmt_txt) values (?,?,?,?,?)\" % BOARD_NAME\n",
    "                cur.execute(sql, (cmt_num,cmt_reply,cmt_writer,cmt_time,cmt_txt))\n",
    "                conn.commit()\n",
    "                conn.close()\n",
    "                \n",
    "        # print(j)\n",
    "        if j > 1:\n",
    "            driver.get('http://m.cafe.daum.net/{0}/{1}/{2}/comments?prev_page={3}&mode=regular&cdepth={4}&page={5}'.format(CAFE_NAME,BOARD_NAME,inp_num,j,'0002100000',(j-1)))\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n",
    "# 열었던 브라우저를 닫아줍니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
